# -*- coding: utf-8 -*-
"""
SafeTalk-MPC - simulation runner

åŠŸèƒ½ï¼š
- è¯»å– DSL(JSON) -> è°ƒç”¨ build_ocp æ„å»º NLP
- è‡ªåŠ¨æ ¹æ® nlp['x'] çš„çœŸå®é•¿åº¦æ„é€ åˆå€¼ï¼ˆå…¼å®¹æ–°å¢ slack å˜é‡ï¼‰
- æ±‚è§£å¹¶ç»˜å›¾/åŠ¨ç”»ï¼Œä¿å­˜æŒ‡æ ‡
- ï¼ˆå¯é€‰ï¼‰ç”¨ LLM å°†è‡ªç„¶è¯­è¨€æŒ‡ä»¤ç¼–è¯‘ä¸º DSL å¢é‡ä¿®æ”¹ï¼ˆæ”¯æŒ ollama å•/å¤šæ¨¡å‹ï¼‰
"""

import os
import sys
import json
import time
import csv
import argparse
import platform
import inspect
import numpy as np
import casadi as ca

# âœ… æ— ç•Œé¢ç¯å¢ƒä¹Ÿèƒ½å‡ºå›¾
import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt

from compiler.build_ocp import build_ocp
from sim.plot_animation import plot_trajectory_animation
from semantics.semantic_compiler import compile_from_text

# å¯é€‰ providerï¼ˆå•æ¨¡å‹ï¼‰
try:
    from semantics.providers.ollama_provider import make_ollama_provider as _mk_single_provider  # å¯èƒ½æ˜¯æ–°/æ—§ç‰ˆæœ¬
except Exception:
    _mk_single_provider = None

# å¯é€‰ providerï¼ˆå¤šæ¨¡å‹/è‡ªä¸€è‡´æ€§ï¼‰
try:
    from semantics.providers.multi_model_provider import make_multi_model_provider as _mk_multi_provider
except Exception:
    _mk_multi_provider = None


# -------------------------
# å·¥å…·å‡½æ•°
# -------------------------
def _load_json(path):
    with open(path, 'r', encoding='utf-8') as f:
        return json.load(f)

def _save_json(obj, path):
    d = os.path.dirname(path)
    if d and not os.path.isdir(d):
        os.makedirs(d, exist_ok=True)
    with open(path, 'w', encoding='utf-8') as f:
        json.dump(obj, f, ensure_ascii=False, indent=2)

def _ensure_dir(p):
    d = os.path.dirname(p)
    if d and not os.path.isdir(d):
        os.makedirs(d, exist_ok=True)

def _ensure_meta(nlp, meta):
    """
    å…¼å®¹ä¸åŒ build_ocp å®ç°ï¼š
    - æ¨èï¼šbuild_ocp -> (nlp, meta)ï¼Œmeta = {'N','nx','nu','bounds':{'lbg','ubg'}, 'obstacle':{...}}
    - æ—§å¼ï¼šbuild_ocp -> (nlp, N, nx, nu) â€”â€” ä»…å…œåº•ï¼Œä¸å»ºè®®ä¾èµ–
    """
    if isinstance(meta, dict) and 'N' in meta:
        if 'bounds' not in meta or 'lbg' not in meta['bounds'] or 'ubg' not in meta['bounds']:
            ng = int(nlp['g'].size1())
            meta.setdefault('bounds', {})
            # âš ï¸ å…œåº•ç­–ç•¥ï¼šå‡å®šæ„é€ çš„çº¦æŸä¸º â€œg >= 0â€
            meta['bounds']['lbg'] = [0.0] * ng
            meta['bounds']['ubg'] = [1e9] * ng
        return meta

    # æ—§æ¥å£å®¹é”™
    if isinstance(meta, (list, tuple)) and len(meta) == 3:
        N, nx, nu = meta
    else:
        try:
            N, nx, nu = meta
        except Exception:
            raise RuntimeError("build_ocp è¿”å›æ ¼å¼ä¸å…¼å®¹ï¼šéœ€è¦ (nlp, meta) æˆ– (nlp, N, nx, nu)")

    ng = int(nlp['g'].size1())
    return {
        'N': int(N),
        'nx': int(nx),
        'nu': int(nu),
        'bounds': {'lbg': [0.0] * ng, 'ubg': [1e9] * ng},
        'obstacle': None
    }

def _jsonable_patch(patch: dict) -> dict:
    """æŠŠ patch é‡Œçš„ tuple è½¬ listï¼Œä¾¿äº JSON ä¿å­˜ã€‚"""
    out = {}
    for k, v in (patch or {}).items():
        out[k] = list(v) if isinstance(v, tuple) else v
    return out

def _append_csv_log(csv_path: str, row: dict):
    header = list(row.keys())
    exists = os.path.isfile(csv_path)
    _ensure_dir(csv_path)
    with open(csv_path, "a", newline="", encoding="utf-8") as f:
        w = csv.DictWriter(f, fieldnames=header)
        if not exists:
            w.writeheader()
        w.writerow(row)


# -------------------------
# Provider å…¼å®¹åŒ…è£…
# -------------------------
def _make_single_provider(model, base_url, temperature, num_predict, seed, save_llm):
    """
    å…¼å®¹ä¸åŒç‰ˆæœ¬çš„ make_ollama_providerï¼š
      æ–°ç‰ˆï¼šmake_ollama_provider(model, base_url, temperature=..., num_predict=..., seed=..., save_dir=...)
      æ—§ç‰ˆï¼šmake_ollama_provider(model, base_url, debug=bool) / (model, base_url)
    """
    if _mk_single_provider is None:
        return None

    sig = inspect.signature(_mk_single_provider)
    kwargs = {"model": model, "base_url": base_url}

    # ä¼˜å…ˆå°è¯•æ–°ç‰ˆå‚æ•°
    if "temperature" in sig.parameters:
        kwargs.update({
            "temperature": float(temperature),
            "num_predict": int(num_predict),
            "seed": int(seed),
        })
        if "save_dir" in sig.parameters and save_llm:
            kwargs["save_dir"] = "llm_logs"
        if "timeout" in sig.parameters:
            kwargs["timeout"] = 120
        if "max_retries" in sig.parameters:
            kwargs["max_retries"] = 2
        try:
            return _mk_single_provider(**kwargs)
        except TypeError:
            pass  # å›é€€åˆ°æ—§ç‰ˆ

    # æ—§ç‰ˆï¼šå¯èƒ½åªæœ‰ debug å‚æ•°
    if "debug" in sig.parameters:
        kwargs["debug"] = bool(save_llm)
        try:
            return _mk_single_provider(**kwargs)
        except TypeError:
            pass

    # æœ€æ—§ï¼šä»… (model, base_url)
    try:
        return _mk_single_provider(model=model, base_url=base_url)
    except TypeError:
        # æœ‰äº›å®ç°æ˜¯ä½ç½®å‚æ•°
        return _mk_single_provider(model, base_url)


def _make_multi_provider(models, base_url, k_samples, temperature, num_predict, seed, save_llm):
    """
    å…¼å®¹ make_multi_model_providerï¼š
      å¸¸è§ç­¾åï¼šmake_multi_model_provider(models, base_url, k_samples, temperature, num_predict, seed, debug_dir=None)
    """
    if _mk_multi_provider is None:
        return None

    sig = inspect.signature(_mk_multi_provider)
    kwargs = {
        "models": models,
        "base_url": base_url,
        "k_samples": int(k_samples),
        "temperature": float(temperature),
        "num_predict": int(num_predict),
        "seed": int(seed),
    }
    if "debug_dir" in sig.parameters and save_llm:
        kwargs["debug_dir"] = "llm_logs"

    try:
        return _mk_multi_provider(**kwargs)
    except TypeError:
        # é€€åŒ–ä¸ºæœ€å°å¿…è¦å‚æ•°
        try:
            return _mk_multi_provider(models, base_url, int(k_samples))
        except TypeError:
            return None


# -------------------------
# æ±‚è§£ + ä½œå›¾
# -------------------------
def solve_and_plot(task_json_path, out_prefix='mpc'):
    """æ„å»º NLP â†’ æ±‚è§£ â†’ ç”»å›¾/åŠ¨ç”» â†’ æŒ‡æ ‡ä¿å­˜ï¼›è¿”å› metrics dictã€‚"""
    print('ğŸ› ï¸ Building MPC problem from DSL...')
    build_ret = build_ocp(task_json_path)

    if isinstance(build_ret, (list, tuple)) and len(build_ret) == 2:
        nlp, meta = build_ret
    else:
        raise RuntimeError("build_ocp å¿…é¡»è¿”å› (nlp, meta)")

    meta = _ensure_meta(nlp, meta)
    N, nx, nu = meta['N'], meta['nx'], meta['nu']
    lbg, ubg = meta['bounds']['lbg'], meta['bounds']['ubg']

    # IPOPT è®¾ç½®
    solver = ca.nlpsol('solver', 'ipopt', nlp, {
        'ipopt.print_level': 0,
        'print_time': 0,
        'ipopt.max_iter': 400,
        'ipopt.tol': 1e-6
    })

    # ====== å…³é”®ä¿®å¤ï¼šæ ¹æ® nlp['x'] çš„çœŸå®é•¿åº¦æ¥æ„é€ åˆå€¼ ======
    n_dec = int(nlp['x'].size1())               # å†³ç­–å˜é‡æ€»é•¿åº¦
    base_len = nx * (N + 1) + nu * N            # åªåŒ…å« X,U æ—¶çš„é•¿åº¦
    extra = n_dec - base_len                     # æ–°å¢çš„å˜é‡ä¸ªæ•°ï¼ˆæ¯”å¦‚ sx, sy -> 2ï¼‰

    if extra < 0:
        raise RuntimeError(f"Internal error: decision size smaller than X/U block. n_dec={n_dec}, base_len={base_len}")

    # å…ˆæŒ‰è€æ–¹å¼æ„é€  X,U çš„åˆå€¼
    x_init = ca.DM.zeros((nx, N + 1))
    u_init = ca.DM.zeros((nu, N))
    init_guess = ca.vertcat(ca.reshape(x_init, -1, 1), ca.reshape(u_init, -1, 1))

    # è‹¥æœ‰æ–°å¢å˜é‡ï¼ˆå¦‚ sx, syï¼‰ï¼Œå†è¡¥ 0
    if extra > 0:
        init_guess = ca.vertcat(init_guess, ca.DM.zeros(extra, 1))
    # ====== ä¿®å¤ç»“æŸ ======

    print('ğŸš€ Solving MPC...')
    t0 = time.time()
    sol = solver(x0=init_guess, lbg=lbg, ubg=ubg)
    t1 = time.time()

    if 'x' not in sol:
        raise RuntimeError("âŒ IPOPT æœªè¿”å›è§£å‘é‡ x")

    x_opt = ca.reshape(sol['x'][:nx * (N + 1)], nx, N + 1)  # (nx, N+1)
    xs = x_opt.T.full()                                    # (N+1, nx)
    xs_xy = xs[:, :2]

    # æŒ‡æ ‡
    task_cfg = _load_json(task_json_path)
    goal = np.array(task_cfg.get('goal', [2, 1, 0, 0, 0]))[:2]
    end_err = float(np.linalg.norm(xs_xy[-1] - goal))
    tot_time = t1 - t0

    # æœ€è¿‘è·ç¦»ï¼ˆå¦‚æœ‰éšœç¢ï¼‰
    obstacle = None
    min_dist = None
    if meta.get('obstacle'):
        cx = float(meta['obstacle']['center'][0])
        cy = float(meta['obstacle']['center'][1])
        r = float(meta['obstacle']['radius'])
        d = np.sqrt((xs_xy[:, 0] - cx) ** 2 + (xs_xy[:, 1] - cy) ** 2)
        min_dist = float(np.min(d))
        obstacle = (cx, cy, r)

    # ç”»é™æ€å›¾
    plt.figure(figsize=(6, 6))
    plt.plot(xs_xy[:, 0], xs_xy[:, 1], 'b-o', ms=3, label='trajectory')
    plt.scatter([xs_xy[0, 0]], [xs_xy[0, 1]], c='g', s=60, label='start')
    plt.scatter([goal[0]], [goal[1]], c='r', s=60, label='goal')
    if obstacle:
        circ = plt.Circle((obstacle[0], obstacle[1]), obstacle[2], color='gray', alpha=0.35, label='obstacle')
        plt.gca().add_patch(circ)
    plt.axis('equal'); plt.grid(True); plt.legend(); plt.title('SafeTalk-MPC Trajectory')
    fig_path = f"{out_prefix}_result.png"
    _ensure_dir(fig_path)
    plt.savefig(fig_path, dpi=150); plt.close()
    print(f"ğŸ“· saved {fig_path}")

    # åŠ¨ç”»ï¼ˆè½¨è¿¹ç‚¹å¤ªå°‘åˆ™è·³è¿‡ï¼‰
    if xs.shape[0] >= 3:
        try:
            anim_path = f"{out_prefix}_anim.mp4"
            plot_trajectory_animation(xs[:, :3], anim_path, obstacle=obstacle or (1.0, 0.5, 0.3))
            print(f"ğŸ¥ saved {anim_path}")
        except Exception as e:
            print(f"âš ï¸ åŠ¨ç”»å¯¼å‡ºå¤±è´¥ï¼ˆå¿½ç•¥ï¼‰ï¼š{e}")
    else:
        fallback = f"{out_prefix}_anim_static.png"
        plt.figure(figsize=(6, 6))
        plt.plot(xs_xy[:, 0], xs_xy[:, 1], 'b-o', ms=3)
        if obstacle:
            circ = plt.Circle((obstacle[0], obstacle[1]), obstacle[2], color='gray', alpha=0.35)
            plt.gca().add_patch(circ)
        plt.axis('equal'); plt.grid(True); plt.title('Animation Fallback')
        _ensure_dir(fallback)
        plt.savefig(fallback, dpi=150); plt.close()
        print(f"ğŸ–¼ï¸ è½¨è¿¹ç‚¹è¿‡å°‘ï¼Œå¯¼å‡ºé™æ€æ›¿ä»£å›¾ï¼š{fallback}")

    # å†™æŒ‡æ ‡
    metrics = {
        'N': int(N),
        'end_position_error': end_err,
        'min_obstacle_distance': min_dist,
        'solve_time_sec': tot_time
    }
    _save_json(metrics, f"{out_prefix}_metrics.json")
    print("ğŸ“‘ metrics:", metrics)
    return metrics


# -------------------------
# CLI
# -------------------------
def build_arg_parser():
    p = argparse.ArgumentParser(description="SafeTalk-MPC simulation runner")
    p.add_argument('task', nargs='?', default='dsl/example_task_curve_01.json',
                   help='DSL JSON path (default: dsl/example_task_curve_01.json)')
    p.add_argument('instruction', nargs='?', default=None,
                   help='Natural language instruction to patch DSL')
    p.add_argument('--out', default='mpc', help='output file prefix (default: mpc)')

    # LLM ç›¸å…³
    p.add_argument('--llm', default='ollama', choices=['none', 'ollama'],
                   help='use local LLM to compile semantics (default: ollama)')
    p.add_argument('--model', default='qwen2.5:3b', help='LLM model name (default: qwen2.5:3b)')
    p.add_argument('--models', default=None,
                   help='comma-separated model list (e.g., "qwen2.5:7b-instruct,llama3.1:8b-instruct")')
    p.add_argument('--k', type=int, default=1, help='samples per model for self-consistency (default: 1)')
    p.add_argument('--temp', type=float, default=0.0, help='LLM temperature (default: 0.0)')
    p.add_argument('--seed', type=int, default=42, help='sampling seed (default: 42)')
    p.add_argument('--base-url', default='http://127.0.0.1:11434', help='Ollama base URL')
    p.add_argument('--save-llm', action='store_true', help='save raw LLM logs to llm_logs/')
    p.add_argument('--risk', default='high', choices=['low', 'med', 'high'],
                   help='risk hint for semantics (default: high)')
    return p


def main():
    args = build_arg_parser().parse_args()
    task_path = args.task
    out_prefix = args.out

    # å¦‚ä¼ äº†è‡ªç„¶è¯­è¨€ï¼Œèµ°è¯­ä¹‰â†’DSL patch
    if args.instruction is not None:
        print(f"ğŸ—£ï¸ Instruction: {args.instruction}")

        provider = None
        if args.llm == 'ollama':
            if args.models:
                if _mk_multi_provider is None:
                    print("âš ï¸ æœªæ‰¾åˆ°å¤šæ¨¡å‹ providerï¼Œæ”¹ç”¨æœ¬åœ°è§„åˆ™å›é€€ã€‚")
                    provider = None
                else:
                    model_list = [m.strip() for m in args.models.split(",") if m.strip()]
                    provider = _make_multi_provider(
                        models=model_list,
                        base_url=args.base_url,
                        k_samples=max(1, args.k),
                        temperature=args.temp,
                        num_predict=256,
                        seed=args.seed,
                        save_llm=args.save_llm
                    )
            else:
                if _mk_single_provider is None:
                    print("âš ï¸ æœªæ‰¾åˆ°å•æ¨¡å‹ providerï¼Œæ”¹ç”¨æœ¬åœ°è§„åˆ™å›é€€ã€‚")
                    provider = None
                else:
                    provider = _make_single_provider(
                        model=args.model,
                        base_url=args.base_url,
                        temperature=args.temp,
                        num_predict=256,
                        seed=args.seed,
                        save_llm=args.save_llm
                    )

        # è¯»å–åŸå§‹ DSL
        original_task = _load_json(task_path) if os.path.isfile(task_path) else task_path

        # è°ƒç”¨è¯­ä¹‰ç¼–è¯‘
        try:
            patched_task, patch = compile_from_text(
                original_task, args.instruction,
                context={'risk_hint': args.risk},
                provider=provider
            )
        except Exception as e:
            print(f"âš ï¸ LLM ç¼–è¯‘å¤±è´¥ï¼Œæ”¹ç”¨æœ¬åœ°è§„åˆ™å›é€€ï¼š{e}")
            patched_task, patch = compile_from_text(
                original_task, args.instruction,
                context={'risk_hint': args.risk},
                provider=None
            )

        # ä¿å­˜ patch & ä¸´æ—¶ DSLï¼Œæ–¹ä¾¿å¤ç°å®éªŒ
        _save_json(_jsonable_patch(patch), "last_patch.json")
        tmp_task = "_tmp_task.json"
        _save_json(patched_task, tmp_task)
        task_path = tmp_task
        print("ğŸ§© LLM patch å·²ä¿å­˜ï¼šlast_patch.json")
        print(f"ğŸ§¾ Patched DSL å·²ä¿å­˜ï¼š{tmp_task}")

    # æ­£å¼æ±‚è§£ + ä½œå›¾
    metrics = solve_and_plot(task_path, out_prefix=out_prefix)

    # è®°å½•ä¸€æ¡å®éªŒæ—¥å¿—
    row = {
        "time": time.strftime("%Y-%m-%d %H:%M:%S"),
        "models": (args.models or args.model) if args.instruction else "",
        "k": args.k,
        "temp": args.temp,
        "seed": args.seed,
        "instruction": args.instruction or "",
        "task": task_path,
        "end_err": metrics.get("end_position_error"),
        "min_dist": metrics.get("min_obstacle_distance"),
        "solve_time": metrics.get("solve_time_sec"),
        "N": metrics.get("N"),
        "machine": platform.platform(),
    }
    try:
        _append_csv_log("llm_runs.csv", row)
        print("ğŸ§¾ appended log to llm_runs.csv")
    except Exception as e:
        print(f"âš ï¸ CSV è®°å½•å¤±è´¥ï¼ˆå¿½ç•¥ï¼‰ï¼š{e}")

    print('âœ… Done.')


if __name__ == '__main__':
    main()
